# LLM-ERM: Sample-Efficient Program Learning via LLM-Guided Search

This repo contains a experiment that prompts an OpenAI GPT-5 model to **synthesize a concise Python function** `f(x)` that matches a hidden target mapping. Datasets are generated from ground-truth functions (binary/decimal, parity/automata/prime/etc.), split deterministically, and persisted to disk. Each model attempt returns code, which is compiled and evaluated; results are logged and exported to JSONL/CSV.

---

## Dependencies

A complete list of dependencies with exact versions is provided in the `environment.yml` file.

---

## Quick start (For a single function - Full Parity)

1) **Set your API key**:

```bash
export OPENAI_API_KEY=sk-...
```

2) **Do Not Run default grid if resources are limited(Runs all task). Instead run the following command.** 

```bash
python runner.py   --functions fn_a   --lengths 100 50 30 25 20 --enable-code-interpreter
```

---

## Replicate entire expriments

1) **Set your API key**:

```bash
export OPENAI_API_KEY=sk-...
```

2) **Run this command to replicate. Note : This is long task, will cost $. It will run all funtions (fn_a fn_b fn_c fn_d fn_e fn_f fn_g fn_h fn_i fn_j fn_k fn_l ) for all the dimenstions (100 50 30 25 20). All other config used in paper are set as default.** 

```bash
python runner.py --enable-code-interpreter
```
---

## CLI usage

```bash
python runner.py   --functions fn_a fn_j fn_i   --lengths 100 50   --attempts 8   --model gpt-5   --max-output-tokens 20000   --concurrency 5   --timeout 1200   --enable-code-interpreter   --verbosity low   --reasoning-effort high   --train-size 100 --val-size 100 --test-size 10000   --seed 42   --dataset-dir datasets   --out-jsonl results_attempts.jsonl   --out-csv results_attempts.csv
```

### Environment variables (defaults)

- `OPENAI_API_KEY` (required)
- `OPENAI_MODEL=gpt-5`
- `MAX_OUTPUT_TOKENS=20000`
- `REASONING_EFFORT=high` (`minimal|medium|high`)
- `TEXT_VERBOSITY=low` (`low|medium|high`)
- `TOOL_CHOICE=auto` (`auto|none`)
- `ENABLE_CODE_INTERPRETER=0` (`1` to enable)
- `CONCURRENCY=5`
- `PER_CALL_TIMEOUT_S=1200`
- `ATTEMPTS=5`
- `TRAIN_SIZE=100`, `VAL_SIZE=100`, `TEST_SIZE=10000`
- `GLOBAL_SEED=42`
- `DATASET_DIR=datasets`
- `OUT_JSONL=results_attempts.jsonl`, `OUT_CSV=results_attempts.csv`
- `LOG_LEVEL=INFO`
- `DRY_RUN=0`

> **Dry run** (`--dry-run` or `DRY_RUN=1`) prints the exact constructed prompt for each query and **does not** call the API.

---

## Targets and functions

`runner.py` uses a compact “experiment ID” → target mapping:

| ID   | `FUNCTION_NAME_MAPPING` target | Domain |
|------|-------------------------------|--------|
| fn_a | `parity_all`                  | binary |
| fn_b | `parity_first_half`           | binary |
| fn_c | `patternmatch1`               | binary |
| fn_d | `patternmatch2`               | binary |
| fn_e | `parity_rand_3`               | binary |
| fn_f | `parity_rand_10`              | binary |
| fn_g | `palindrome`                  | binary |
| fn_h | `dyck2`                       | binary (lengths: `[100,80,60,40,20]`) |
| fn_i | `prime_decimal`               | **decimal** |
| fn_j | `automata_parity`             | binary |
| fn_k | `prime_decimal_tf_check`      | **decimal** |
| fn_l | `sha256_parity`               | binary |

Targets flagged as decimal are listed in `DECIMAL_FNS = {"prime_decimal", "prime_decimal_tf_check"}` and receive a decimal problem statement.

---

## Data generators (high-level)

All generators return a list of dicts:
```python
{'Input': np.array([... as strings ...]), 'Output': '0' or '1'}
```

- **`BinaryDataGenerator`**  
  Balanced 50/50 label split **by construction** against any registered function in `TARGET_FUNCTIONS`.  
  Efficient uniqueness + balancing loop; CPU set-ops for dedup; shuffles final dataset.

- **`PalindromeDataGenerator`**  
  Half palindromes, half non-palindromes (generated by flipping one bit in first half).

- **`PatternBasedDataGenerator`**  
  Balanced presence/absence of a configurable pattern (defaults to `10101010`).  
  Generates with-pattern by insertion; generates without-pattern by “repairing” collisions.

- **`Dyck2DataGenerator`**  
  Balanced valid/invalid Dyck-2 sequences; invalids are near-miss corruptions of valids.  
  Sequence length must be a multiple of 4 (2 bits/paren; pairs become `()[]`).

- **Prime (decimal) families**  
  - `PrimeDataGenerator` — balanced primes vs non-primes (random sampling + `sympy`).  
  - `PrimeDecimalTailRestrictedDataGenerator` — primes vs **non-primes ending with {1,3,7,9}**.  

See **`src/data_handler.py`** for constructor signatures and invariants (e.g., many require `num_samples` to be **even**).

---

## Design notes & invariants

- **Balancing**: most generators create exactly half positives/negatives to make accuracy comparable and stable.
- **Lengths**: Dyck-2 requires `sequence_length % 4 == 0`; runner special-cases `fn_h`.
- **Decimal vs binary**: affects prompt only; datasets are always rendered as strings: `'0'/'1'` for binary bits, `'0'..'9'` for decimal digits.

---
